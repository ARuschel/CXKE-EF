{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "\tos.chdir(os.path.join('/home/andrey/proj/OpenKE/'))\n",
    "\tprint('Current working dir:', os.getcwd())\n",
    "except:\n",
    "\tpass\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tools.tools import get_dirs, write_to_pkl, load_file, restore_model\n",
    "from tools.dataset_tools import Dataset\n",
    "from tools.explainer import Explainer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sfe_ar.tools.helpers import generate_timestamp\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "get_ipython().magic(u'load_ext autoreload')\n",
    "get_ipython().magic(u'autoreload 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SFE Timestamps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "splits = 'g_2negrate_bern'\n",
    "timestamp_emb = '1906141142'\n",
    "timestamp_sfe = '2010150748'\n",
    "dataset = 'FB15K237'\n",
    "emb_model = 'TransE'\n",
    "kv_model = 'fb15k237_Google_news_d300.model'\n",
    "\n",
    "# timestamp_sfe = '2010161223'\n",
    "# dataset = 'NELL186'\n",
    "# emb_model = 'Analogy'\n",
    "# timestamp_emb = '1904121223'\n",
    "# kv_model = 'word2vec/NELL186_Google_news_d300.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "e = Explainer(dataset, \n",
    "                emb_model, \n",
    "                timestamp_emb, \n",
    "                timestamp_sfe,\n",
    "                splits, \n",
    "                method='fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "e.load_kv_model(kv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_logit = [{\n",
    "            'l1_ratio': [.1, .5, .7, .9, .95, .99, 1],\n",
    "            'alpha': [0.01, 0.001, 0.0001],\n",
    "            'loss': [\"log\"],\n",
    "            'penalty': [\"elasticnet\"],\n",
    "            'max_iter': [100000],\n",
    "            'tol': [1e-3],\n",
    "            'class_weight': [\"balanced\"],\n",
    "            'n_jobs': [10]\n",
    "}]\n",
    "\n",
    "e.set_param_grid_logit(param_grid_logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "e.set_prune_dict(\n",
    "    {\n",
    "        'pru:prunning':'force',\n",
    "        # 'pru:node_relv_in':False,\n",
    "        'pru:top_pop': 0.2,\n",
    "        # 'pru:top_avg_rel_sim': 0.2,\n",
    "        'xke:evaluate_benchmarks':False\n",
    "    }\n",
    ")\n",
    "\n",
    "e.train_test_logit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.logit_models['r0']['xke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Build X_test_pred Bench Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = e.logit_results_folder + '2011192127/'\n",
    "xke_model = e.load_from_pkl(model_folder + 'logit_models')\n",
    "xke = xke_model['r82']\n",
    "feature_names = np.array(xke['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = xke['X_test'].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(X[xke['y_test_emb'] == 1].sum(axis=0))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = xke['xke'].coef_[0]\n",
    "intercept = xke['xke'].intercept_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(index=feature_names)\n",
    "features['coefs'] = coefs\n",
    "features.reset_index(inplace=True)\n",
    "features.rename(columns={'index':'path'}, inplace=True)\n",
    "features['idx'] = features.index\n",
    "features.set_index('path', inplace=True)\n",
    "features.sort_values(by='coefs', ascending=False, inplace=True)\n",
    "features = features[features['coefs'] != 0]\n",
    "\n",
    "pos_features = features[features['coefs'] > 0]\n",
    "pos_features.sort_values(by='coefs', ascending=False, inplace=True)\n",
    "print('pos_features has {} features.'.format(len(pos_features)))\n",
    "\n",
    "neg_features = features[features['coefs'] < 0]\n",
    "neg_features.sort_values(by='coefs', ascending=True, inplace=True)\n",
    "print('neg_features has {} features.'.format(len(neg_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = X[0].toarray()[0]\n",
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xke['xke'].decision_function(X[0].toarray())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (x0 != 1) & (coef > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = feature_names[mask]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pos_features = features[features.index.isin(selected_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_features = list(selected_pos_features.index.values)\n",
    "f_coefs = list(selected_pos_features.coefs.values)\n",
    "f_idx = list(selected_pos_features.idx.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xke['xke'].intercept_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef[(x0 == 1) & (coef != 0)].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xke['xke'].decision_function(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef[coef > 0].sum() + intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef[coef<0].sum() + intercept"
   ]
  },
  {
   "source": [
    "## Explanations file bench test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ , _, X_test, y_test, y_test_emb, _, _, _ , _ , feature_names2, test_triples = e.fast_load_data(e.rel_dict['r82'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = e.logit_results_folder + '2011240652/'\n",
    "xke_model = e.load_from_pkl(model_folder + 'logit_models')\n",
    "xke = xke_model['r82']\n",
    "feature_names = np.array(xke['feature_names'])\n",
    "XKEe_X_test = xke['XKEe_X_test']\n",
    "coefs = xke['xke'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_model = pd.read_csv(model_folder + 'r82_coefs.tsv', sep='\\t', index_col=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "from csv import writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['triple_id', 'triple', 'label', 'emb_label', 'XKE_label', 'XKEe_label', 'sim_index', 'coef', 'g_hat', 'explanation']\n",
    "\n",
    "output = StringIO()\n",
    "csv_writer = writer(output)\n",
    "\n",
    "emb_labels = xke['y_test_emb']\n",
    "xke_labels = xke['xke'].predict(X_test.toarray())\n",
    "xkee_labels = xke['xke'].predict(XKEe_X_test.todense())\n",
    "\n",
    "j = 0\n",
    "for triple_id, emb_label, xke_label, xkee_label in zip(test_triples, emb_labels, xke_labels, xkee_labels):\n",
    "    triple = triple_id.split('_')\n",
    "    triple_descr = str(e.ent_dict[triple[0]]) + ' | ' + str(e.ent_dict[triple[1]])\n",
    "    label = triple[2]\n",
    "\n",
    "    mask = np.array((X_test[j].todense() != 0) & (coefs != 0))[0]\n",
    "\n",
    "    active_features = feature_names[mask]\n",
    "\n",
    "    for feature in active_features:\n",
    "        csv_writer.writerow([triple_id]+[triple_descr]+[label]+[emb_label]+[xke_label]+[xkee_label]+[explain_model.loc[feature, 'avg_rel_sim']]+[explain_model.loc[feature, 'coef']] + [0] + [e.explain_path(feature)])\n",
    "\n",
    "    new_mask = np.array((XKEe_X_test.todense()[j] > X_test.todense()[j]) & (coefs != 0))[0]\n",
    "\n",
    "    active_features = feature_names[new_mask]\n",
    "\n",
    "    for feature in active_features:\n",
    "        csv_writer.writerow([triple_id]+[triple_descr]+[label]+[emb_label]+[xke_label]+[xkee_label]+[explain_model.loc[feature, 'avg_rel_sim']]+[explain_model.loc[feature, 'coef']]+ [1] + [e.explain_path(feature)])\n",
    "    j += 1 \n",
    "   \n",
    "output.seek(0)\n",
    "df = pd.read_csv(output, sep=',',names=cols)\n",
    "print(f'DataFrame with {df.shape[0]} rows and {df.shape[1]} cols.')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoide(df[df['triple_id'] == test_triples[3]].sort_values(by='coef', ascending=False).coef.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoide(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.emb.test_step([193], [1771], [82])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bench Test"
   ]
  },
  {
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "\tos.chdir(os.path.join('/home/andrey/proj/OpenKE/'))\n",
    "\tprint('Current working dir:', os.getcwd())\n",
    "except:\n",
    "\tpass\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tools.tools import get_dirs, write_to_pkl, load_file, restore_model\n",
    "from tools.dataset_tools import Dataset\n",
    "from tools.explainer import Explainer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sfe_ar.tools.helpers import generate_timestamp\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "get_ipython().magic(u'load_ext autoreload')\n",
    "get_ipython().magic(u'autoreload 2')# Tensorflow Experiments\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timestamp_emb = '1906141142_a'\n",
    "timestamp_sfe = '2010150748'\n",
    "dataset = 'FB15K237'\n",
    "emb_model = 'TransE'\n",
    "\n",
    "e = Explainer(dataset, emb_model, timestamp_emb, timestamp_sfe, method='fast')\n",
    "e.load_true_sets()\n",
    "e.build_graph()\n",
    "e.load_kbe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.emb.enhanced_true_tails([72], 82, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.emb.classify(72, 82, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.emb.test_step([72], [44], [82])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nonzero(e.emb.get_true_tails_np([72], 82))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.names_dict['e72']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.emb.calculate_thresholds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.emb.relThresh[82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [0, 1]\n",
    "rel = 82\n",
    "rel_thresh = e.emb.relThresh[82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.emb.optimized_node_expansion(nodes, rel, rel_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.emb.classify_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([True, True, False], tf.bool)\n",
    "b = tf.constant([True, False, False], tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "\n",
    "    print(sess.run(tf.math.logical_or(a, b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = tf.constant(0, shape=(e.emb.entTotal,))\n",
    "r = tf.constant(82, shape=(e.emb.entTotal,))\n",
    "t = tf.range(start=0, limit=e.emb.entTotal, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = tf.constant([3])\n",
    "e = tf.reshape(d, shape=)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "\n",
    "start = time.time()\n",
    "h = np.array([72] * (e.emb.entTotal * n))\n",
    "r = np.array([82] * (e.emb.entTotal * n))\n",
    "t = np.array(list(range(e.emb.entTotal * n)))\n",
    "\n",
    "with e.emb.graph.as_default():\n",
    "    with e.emb.sess.as_default():\n",
    "\n",
    "        feed_dict = {\n",
    "            e.emb.trainModel.predict_h: h,\n",
    "            e.emb.trainModel.predict_t: t,\n",
    "            e.emb.trainModel.predict_r: r,\n",
    "        }\n",
    "        res = e.emb.sess.run(e.emb.trainModel.predict, feed_dict)\n",
    "\n",
    "print(f'Elapsed time: {time.time() - start}')\n",
    "print(f'res has len={len(res)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 300\n",
    "\n",
    "start = time.time()\n",
    "h = np.array(list(range(n)))\n",
    "r = 82\n",
    "\n",
    "with e.emb.graph.as_default():\n",
    "    with e.emb.sess.as_default():\n",
    "\n",
    "        feed_dict = {\n",
    "            # h_e:h,\n",
    "            # r_e:r\n",
    "        }\n",
    "        for i in h:\n",
    "            e.emb.h = i\n",
    "            res = e.emb.sess.run(e.emb.trainModel.predict, feed_dict)\n",
    "\n",
    "print(f'Elapsed time: {time.time() - start}')\n",
    "print(f'res has len={len(res)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "hs = np.array(list(range(n)), dtype=np.int32)\n",
    "rs = 82\n",
    "rel_thresh = e.emb.relThresh[82]\n",
    "hs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = tf.FIFOQueue(capacity=10, \n",
    "                dtypes=tf.int32,\n",
    "                shapes=[])\n",
    "enqueue_op = q.enqueue_many(hs)\n",
    "qr = tf.train.QueueRunner(q, [enqueue_op] * 1)\n",
    "tf.train.add_queue_runner(qr)\n",
    "\n",
    "node = q.dequeue()\n",
    "node_to_expand = tf.reshape(node, shape=(1,))\n",
    "\n",
    "t = tf.range(start=0, limit=e.emb.entTotal, dtype=tf.int32)\n",
    "\n",
    "rel = tf.constant(rs, shape=(1,))\n",
    "\n",
    "n_ents = tf.constant([e.emb.entTotal])\n",
    "heads = tf.tile(node_to_expand, n_ents)\n",
    "rels = tf.tile(rel, n_ents)\n",
    "\n",
    "data = tf.Print([heads], data=[heads, rels, t, tf.shape(heads)], message='This is how many items are left in q: ')\n",
    "# # h = tf.reshape(node_to_expand, shape=(e.emb.entTotal,))\n",
    "# r = tf.constant(rs, shape=(e.emb.entTotal,), dtype=tf.int32)\n",
    "# t = tf.range(start=0, limit=e.emb.entTotal, dtype=tf.int32)\n",
    "fg = data + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    for i in range(len(hs)):\n",
    "        sess.run(fg)\n",
    "    print(\"We're here!\")\n",
    "\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "\n",
    "print(f'Elapsed time: {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/38856292/tensorflow-queue-feed-order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h = np.array([1, 2, 3])\n",
    "r = np.array([3])\n",
    "n_ents = 10\n",
    "thres = 0.17\n",
    "\n",
    "t_h = tf.placeholder(tf.int64)\n",
    "t_ents = tf.constant([n_ents])\n",
    "t_heads = tf.constant([1, len(h)])\n",
    "\n",
    "t_hh = tf.reshape(tf.tile(t_h, t_ents), [n_ents, len(h)])\n",
    "t_rr = tf.constant(r, tf.int64, shape=(n_ents, len(h)))\n",
    "t_tt = tf.tile(tf.reshape(tf.range(start=0, limit=n_ents, dtype=tf.int64), [n_ents, 1]), t_heads)\n",
    "\n",
    "out = t_hh + t_rr + t_tt\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "\n",
    "    print(sess.run(out, feed_dict={t_h:h}))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros(shape=(14500, 14500), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(a) / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(e.emb.build_rel_ghat(82, e.emb.relThresh[82]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.emb.entTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heads = np.array(list(range(e.emb.entTotal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "e.emb.enhanced_true_tails(heads, 82, e.emb.relThresh[82])\n",
    "\n",
    "print(f'Finished process in {time.time() - start}s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.zeros(shape=(e.emb.entTotal, e.emb.entTotal), dtype=np.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = e.emb.build_emb_rel_matrix(heads, 82, e.emb.relThresh[82])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.nonzero(r[:, 44])[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.ent_dict['e44']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    np.dot(x[44].todense(), x[44].T.todense())\n",
    "print(f'Elapsed Time: {time.time() - start}s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    set(np.nonzero(x[44])[0].tolist()).isdisjoint(set(np.nonzero(x[44])[0].tolist()))\n",
    "print(f'Elapsed Time: {time.time() - start}s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.nonzero(x.T[44])[1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.3 * 237"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(x[72].todense(), x[44].T.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_graph = sparse.lil_matrix(np.zeros(shape=(e.emb.entTotal, e.emb.entTotal), dtype = np.bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dict()\n",
    "for rel in range(237):\n",
    "    graph[rel] = empty_graph.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rels = [82, 23, 0]\n",
    "\n",
    "for rel in rels:\n",
    "    graph[rel][:] = e.emb.build_emb_rel_matrix(heads, rel, e.emb.relThresh[rel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph[82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(237):\n",
    "    print(f'rel {i} : {e.emb.relThresh[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "x = graph[82]\n",
    "y = graph[82].T\n",
    "\n",
    "for _ in range(100):\n",
    "    np.nonzero(x[44])[1].tolist()\n",
    "print(f'Elapsed Time: {time.time() - start}s.')\n",
    "len(np.nonzero(x[44])[1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(graph[220])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nonzero(graph[82][44])[1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.random.randint(0, 10, size=(10, 10))\n",
    "matrix[4] = 0\n",
    "matrix[2, 2:5] = 0\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(shape=(10), dtype=np.bool)\n",
    "heads = [2, 4]\n",
    "mask[heads] = 1\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix[:, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nonzero(matrix[:, mask].sum(axis=1))[0].tolist()"
   ]
  },
  {
   "source": [
    "# PathFinder BenchTest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current working dir: /media/andrey/2a3d8a6c-48b6-437b-9410-7c45ccb1c802/andrey/proj/OpenKE\n",
      "/home/andrey/miniconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/andrey/miniconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/andrey/miniconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/andrey/miniconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/andrey/miniconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/andrey/miniconda3/envs/tf14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/andrey/miniconda3/envs/tf14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/andrey/miniconda3/envs/tf14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/andrey/miniconda3/envs/tf14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/andrey/miniconda3/envs/tf14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/andrey/miniconda3/envs/tf14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/andrey/miniconda3/envs/tf14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "\tos.chdir(os.path.join('/home/andrey/proj/OpenKE/'))\n",
    "\tprint('Current working dir:', os.getcwd())\n",
    "except:\n",
    "\tpass\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from tools.tools import get_dirs, write_to_pkl, load_file, restore_model\n",
    "from tools.dataset_tools import Dataset\n",
    "from tools.explainer import Explainer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sfe_ar.tools.helpers import generate_timestamp\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "get_ipython().magic(u'load_ext autoreload')\n",
    "get_ipython().magic(u'autoreload 2')# Tensorflow Experiments\n",
    "\n",
    "import sys\n",
    "import time\n",
    "# import tensorflow as tf\n",
    "# print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded FB15K237 Dataset with 14541 entities and 474 relations.\n",
      "\n",
      "\n",
      "Loaded sfe_model_info!\n",
      "Loaded emb_model_info for 1906141142 timestamp!\n",
      "Loaded Keyed-Vectors Similarity Model.\n",
      "Computed rel and ent similarity matrices.\n",
      "\n",
      "Building FB15K237 graph... loading triples... Loading FB15K237 true facts...  Done!\n",
      "\n",
      "Train set has 272115 triples\n",
      "Test set has 20466 triples\n",
      "Valid set has 17535 triples\n",
      "Done!\n",
      "\n",
      "Graph built with 579300 edges.\n",
      "Loadding g_hat file... Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = 'FB15K237'\n",
    "splits = 'g_2negrate_bern'\n",
    "kv_model = 'fb15k237_Google_news_d300.model'\n",
    "\n",
    "emb_model = 'TransE'\n",
    "timestamp_emb = '1906141142'\n",
    "timestamp_sfe = '2009262117'\n",
    "\n",
    "param_grid_logit = [{\n",
    "            'l1_ratio': [.1, .5, .7, .9, .95, .99, 1],\n",
    "            'alpha': [0.01, 0.001, 0.0001],\n",
    "            'loss': [\"log\"],\n",
    "            'penalty': [\"elasticnet\"],\n",
    "            'max_iter': [100000],\n",
    "            'tol': [1e-3],\n",
    "            'class_weight': [\"balanced\"],\n",
    "            'n_jobs': [10]\n",
    "}]\n",
    "params = {'pru:prunning':'force', 'xke:evaluate_benchmarks':False, 'pru:top_avg_rel_sim': 0.1}\n",
    "\n",
    "\n",
    "e = Explainer(dataset, \n",
    "                emb_model, \n",
    "                timestamp_emb, \n",
    "                timestamp_sfe,\n",
    "                splits, \n",
    "                method='fast')\n",
    "\n",
    "e.load_kv_model(kv_model)\n",
    "e.set_param_grid_logit(param_grid_logit)\n",
    "e.set_prune_dict(params)\n",
    "e.build_graph()\n",
    "e.load_g_hat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 237/237 [00:24<00:00,  9.86it/s]Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "e.build_g_hat_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'r48'\n",
    "triple = 'e72_e2410_1_r82'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\nFinished in 0.023296833038330078 seconds.\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "print(e.build_emb_path(triple, path))\n",
    "print(f'Finished in {time.time()-t1} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\nFinished in 0.00027823448181152344 seconds.\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "print(e.path_builder(triple, path))\n",
    "print(f'Finished in {time.time()-t1} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{2}"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "{2, 5} & {2, 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['e2410']"
      ]
     },
     "metadata": {},
     "execution_count": 113
    }
   ],
   "source": [
    "e.graph['e72']['r48']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}